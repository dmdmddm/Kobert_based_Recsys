{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOsuEA/BhbWDn8VhxZcJQ0e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EoflGx9oC8dE"},"source":["#초기 환경 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29406,"status":"ok","timestamp":1703176547292,"user":{"displayName":"김동민","userId":"03761462136668939710"},"user_tz":-540},"id":"-738r3p9DA38","outputId":"c2e0f428-7c17-411b-cbda-bad44704844b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# 구글 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3BFQS4GwHgpC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703176595876,"user_tz":-540,"elapsed":48591,"user":{"displayName":"김동민","userId":"03761462136668939710"}},"outputId":"fa619b77-8b54-4cf4-8ca1-1f977ca523ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mxnet\n","  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.23.5)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.31.0)\n","Collecting graphviz<0.9.0,>=0.8.1 (from mxnet)\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2023.11.17)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.20.1\n","    Uninstalling graphviz-0.20.1:\n","      Successfully uninstalled graphviz-0.20.1\n","Successfully installed graphviz-0.8.4 mxnet-1.9.1\n","Collecting gluonnlp==0.8.0\n","  Downloading gluonnlp-0.8.0.tar.gz (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gluonnlp==0.8.0) (1.23.5)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.8.0-py3-none-any.whl size=292697 sha256=03aa8e1206ba60eed98a40b3dd807030662aa873d10c5b778b8770758be85cb7\n","  Stored in directory: /root/.cache/pip/wheels/2d/cc/dc/7ec84dced25f738b8be400101abb67e4b50c905090a51017e4\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.8.0\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"]}],"source":["# 필요 패키지 설치\n","!pip install mxnet\n","!pip install gluonnlp==0.8.0\n","!pip install tqdm pandas\n","!pip install sentencepiece\n","!pip install transformers\n","!pip install torch>=1.8.1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8126,"status":"ok","timestamp":1703176603993,"user":{"displayName":"김동민","userId":"03761462136668939710"},"user_tz":-540},"id":"GQCfrXMXJt2T","outputId":"fc5aa7e4-e335-48e4-b0fc-9963a1b7a64e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kobert_tokenizer\n","  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-hothe5r4/kobert-tokenizer_0df9b224445d402896059c96fe11f185\n","  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-hothe5r4/kobert-tokenizer_0df9b224445d402896059c96fe11f185\n","  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: kobert_tokenizer\n","  Building wheel for kobert_tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert_tokenizer: filename=kobert_tokenizer-0.1-py3-none-any.whl size=4632 sha256=a39e9bac682a48cf526020f931360665272e42b770e198f4cabe7de2c1e8f60d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-3thu30jq/wheels/e9/1a/3f/a864970e8a169c176befa3c4a1e07aa612f69195907a4045fe\n","Successfully built kobert_tokenizer\n","Installing collected packages: kobert_tokenizer\n","Successfully installed kobert_tokenizer-0.1\n"]}],"source":["# Kobert 실행\n","!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gBa_fEwq6Sil"},"outputs":[],"source":["# 필요 패키지 import 1\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","import pandas as pd\n","import json\n","\n","# transformers\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup"]},{"cell_type":"code","source":["# 필요 패키지 import 2\n","!pip install xmltodict\n","\n","import xmltodict\n","import requests"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acFfiXMvBURE","executionInfo":{"status":"ok","timestamp":1703176622369,"user_tz":-540,"elapsed":6954,"user":{"displayName":"김동민","userId":"03761462136668939710"}},"outputId":"d75b6da3-ab3e-4824-97cb-b43554320c32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting xmltodict\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Installing collected packages: xmltodict\n","Successfully installed xmltodict-0.13.0\n"]}]},{"cell_type":"markdown","source":["### no mouduled kobert 문제 해결\n","- Hugging Face를 통한 모델 및 토크나이저 Import\n","- 출처 : https://blog.naver.com/newyearchive/223097878715"],"metadata":{"id":"WOOFy7j5ZDsv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-dsQhaz8KOWb"},"outputs":[],"source":["from kobert_tokenizer import KoBERTTokenizer\n","from transformers import BertModel\n","\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":233,"referenced_widgets":["3d418cea075548f296513bd740415d97","e68ef330548a471bbdc8848ce1c560da","5705f5a06ac4443fa9e12f198e2a4ca7","640e65a222f84287a9cf1663c2ace715","abf985bb781f4b4fbce80b1f2e742b3c","7ab1ab2c892d450085dcc867b15d56bb","a5e3de5eb348407bb2de67d25f394d21","ae4d7b35efbe4710a7ef1e7761550a04","2c6362a97f854bfda8ac74dc9484083b","f57ee99b0e81428d9568c2b440bdc652","7791a1c702ce4f51a71aa54638e3a9ff","b3c4d44a3b1247bdbe61727047da1941","9c2ab5bce5b64c468c12641559de5e30","0e71555048054316981712f90621866e","88fba6b6d78642ec9f25e50e45958421","ec85c4c4fd084659abeefb30ad3fa722","1e285a1e89094814bf171795c0f9ba0c","01d078f05975424ab97962312283e657","16369da4f01448d7972889e4ba861562","92a3bb5991a248c2823e276a6fe88ef9","84126b41771f448d847c6a4930975e3c","7bc4f78fb17d41eca5f5d7c0122b6f82","92bc51d1709548b2b9f3507d7e53d8fe","c71a67d109df4f0a9e5b0bbcaab260b7","08022e94552b4e7c995cdee3b262dcee","5250eef23f9b482885c783a9c37aed42","a5da66c9b3754dab8168d85b7193f9a0","410fe0f8651543e09edc06c98dccdf8b","e3ca61302cb747b4a5d167f714c7e2bc","908403b323494d20a7e32cbb873070c7","9279ed86c3704ab389851b6f0a256580","9314e939e9e049ae8053e7d4395c7ed4","784a4293b0294a6db10978744df4bc2c","cff09dd5f0ae4fed896034355ef85f03","fe8c59c99bae41fd87c7d5a0a43c1147","01df6660b7924abaa24281a3bd2120d8","be0c08a5c06e49629d32bfe5e7becfea","d70a7903731741c89f56a96d0420de05","b65e7b207cbc46b2bfe8bbd60ef48c2e","141799eabd2941969b86cb8987f5a8be","c6310b45c43d4fcf994cbbb887ecb10e","5314b7865a1141f4be0688c2b31b7bdb","5476e882f0c04668a52826a0a7150147","bb0e02f5ae4c40e88765c68a877d11fe","1b63bcfa4e184875adfa26d2508878ff","70319e3b70354c8eab354684d56cf437","bac0cbbd1d41417d82bf52b25afdd9d3","3d7e33d4de614511bc8132b7919b10ed","835606fcdeed491da1f39eccd7f8d508","7e0be86fdb1e44ccb84f2262cf70b3f6","662abd92a61b411d8c43749a02470713","f1cb8a587c7f48338ea699cd8ca24058","35ba928c67cc45fcb7ce381279bd7596","552d5e34b2b143ce961cd36b9dbd4fec","cc2b81c98c4b4fc0b13b9ecca8e0c425"]},"executionInfo":{"elapsed":41604,"status":"ok","timestamp":1703176664762,"user":{"displayName":"김동민","userId":"03761462136668939710"},"user_tz":-540},"id":"ia9pAZzmLu6l","outputId":"1aef61c8-a5c1-4583-a9d7-f95ce44cc736"},"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d418cea075548f296513bd740415d97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/371k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3c4d44a3b1247bdbe61727047da1941"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/244 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92bc51d1709548b2b9f3507d7e53d8fe"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/535 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cff09dd5f0ae4fed896034355ef85f03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/369M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b63bcfa4e184875adfa26d2508878ff"}},"metadata":{}}],"source":["# 모델 객체 생성\n","# 토크나이저와 bertmodel 우회 생성\n","tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n","bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n","vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')"]}]}